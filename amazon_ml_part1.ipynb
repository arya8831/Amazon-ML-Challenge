{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRuS3ZOA-UZd",
        "outputId": "7dadf467-42c0-4fd4-952a-92828aeb58cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text chunks have been written to /content/output.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "# Path to the input text file and output CSV file\n",
        "input_file_path = '/content/Arya extraction.txt'\n",
        "output_csv_path = '/content/output.csv'\n",
        "\n",
        "# Open the input file and read the content\n",
        "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Split the content based on the pattern \"========================================\"\n",
        "chunks = content.split(\"========================================\")\n",
        "\n",
        "# Remove leading/trailing whitespaces from each chunk\n",
        "chunks = [chunk.strip() for chunk in chunks if chunk.strip()]\n",
        "\n",
        "# Write the chunks to a CSV file, each chunk in a new row\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write each chunk as a separate row in the CSV\n",
        "    for chunk in chunks:\n",
        "        writer.writerow([chunk])\n",
        "\n",
        "print(f\"Text chunks have been written to {output_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "# Function to extract the relevant substring from image link\n",
        "def extract_image_name(image_link):\n",
        "    return image_link.split('/')[-1]  # Get the part after the last \"/\"\n",
        "\n",
        "# Function to extract entity value based on entity_name from text\n",
        "def extract_entity_value(entity_name, text):\n",
        "    # Define extended patterns for different entities\n",
        "    patterns = {\n",
        "        'weight': r'(\\d+(?:[\\.,]\\d+)?)\\s*(G|GRAMS?|GMS?|KG|KILOGRAMS?|OZ|OUNCES?)',\n",
        "        'width': r'(\\d+(?:[\\.,]\\d+)?)\\s*(CM|MM|M|METERS?|KM|KILOMETERS?|INCH(?:ES)?|IN|FT|FEET)',\n",
        "        'height': r'(\\d+(?:[\\.,]\\d+)?)\\s*(CM|MM|M|METERS?|KM|KILOMETERS?|INCH(?:ES)?|IN|FT|FEET)',\n",
        "        'length': r'(\\d+(?:[\\.,]\\d+)?)\\s*(CM|MM|M|METERS?|KM|KILOMETERS?|INCH(?:ES)?|IN|FT|FEET)',\n",
        "        'power': r'(\\d+(?:[\\.,]\\d+)?)\\s*(W|WATT(?:S)?)',\n",
        "        'voltage': r'(\\d+(?:[\\.,]\\d+)?)\\s*(V|VOLTS?)',\n",
        "        'speed': r'(\\d+(?:[\\.,]\\d+)?)\\s*(KM/H|KMH|MPH|MILES? PER HOUR|KILOMETERS? PER HOUR)',\n",
        "        'volume': r'(\\d+(?:[\\.,]\\d+)?)\\s*(L|LITERS?|ML|MILLILITERS?)',\n",
        "    }\n",
        "\n",
        "    # Match the correct pattern based on the entity name\n",
        "    pattern = patterns.get(entity_name.lower(), None)\n",
        "    if pattern:\n",
        "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "        # Format the results as \"value unit\"\n",
        "        return ', '.join([f\"{value.replace(',', '.')} {unit.upper()}\" for value, unit in matches])\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "# Step 1: Read test.csv and output.csv\n",
        "test_csv_path = 'test.csv'\n",
        "output_csv_path = 'output.csv'\n",
        "output_dev_csv_path = 'test_dev.csv'\n",
        "\n",
        "# Load test.csv into a list of dictionaries\n",
        "with open(test_csv_path, 'r', encoding='utf-8') as test_file:\n",
        "    test_data = list(csv.DictReader(test_file))\n",
        "\n",
        "# Load output.csv into a list\n",
        "with open(output_csv_path, 'r', encoding='utf-8') as output_file:\n",
        "    output_data = [row['column_name'] for row in csv.DictReader(output_file)]  # Assuming column header as 'column_name'\n",
        "\n",
        "# Step 2: Process each row of test.csv and match it with output.csv\n",
        "with open(output_dev_csv_path, 'w', newline='', encoding='utf-8') as dev_file:\n",
        "    fieldnames = ['index', 'prediction']\n",
        "    writer = csv.DictWriter(dev_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()  # Write the header\n",
        "\n",
        "    # Loop through each row in test.csv\n",
        "    for row in test_data:\n",
        "        index = row['index']\n",
        "        image_link = row['image_link']\n",
        "        entity_name = row['entity_name']\n",
        "\n",
        "        # Extract the image name from the image link\n",
        "        image_name = extract_image_name(image_link)\n",
        "        prediction = \"\"\n",
        "\n",
        "        # Step 3: Search for a matching entry in output.csv\n",
        "        matching_text = next((text for text in output_data if image_name in text), None)\n",
        "\n",
        "        # If a match is found, extract the entity value\n",
        "        if matching_text:\n",
        "            prediction = extract_entity_value(entity_name, matching_text)\n",
        "\n",
        "        # Step 4: Write the index and prediction to the test_dev.csv file\n",
        "        writer.writerow({'index': index, 'prediction': prediction if prediction else \"\"})\n"
      ],
      "metadata": {
        "id": "Jy7rY5i-_C5j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}